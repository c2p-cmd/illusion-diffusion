{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    StableDiffusionImg2ImgPipeline\n",
    ")\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "from ip_adapter import IPAdapter\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print (\"CUDA & MPS devices not found.\")\n",
    "\n",
    "print(\"Testing torch device\")\n",
    "torch.ones(2, device=device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"stabilityai/sd-vae-ft-mse\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Diffusion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# stable diffusion pipeline\n",
    "# pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "#     \"SG161222/Realistic_Vision_V4.0_noVAE\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     safety_checker=None\n",
    "# )\n",
    "\n",
    "pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"timbrooks/instruct-pix2pix\",\n",
    "    vae=vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None\n",
    ")\n",
    "pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)\n",
    "pipeline = pipeline.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the ip_adapter and the image_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "# hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"models/ip-adapter_sd15.bin\", local_dir_use_symlinks=False, local_dir=\"./\")\n",
    "# hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"models/image_encoder/config.json\", local_dir_use_symlinks=False, local_dir=\"./\")\n",
    "# hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"models/image_encoder/pytorch_model.bin\", local_dir_use_symlinks=False, local_dir=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IP Adapter for Image Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ip-adapter\n",
    "ip_model = IPAdapter(pipeline, \"models/image_encoder/\", \"models/ip-adapter_sd15.bin\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = (608, 768)\n",
    "from PIL import Image\n",
    "\n",
    "image1 = Image.open(\"../input/IMG_0521.png\")\n",
    "image2 = load_image(\"../outputs/beach2.png\")\n",
    "\n",
    "image2 = image2.resize(image1.size)\n",
    "image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image=image1\n",
    "prompt=image2\n",
    "negative_prompt=\"nsfw, bad quality, bad anatomy, worst quality, low quality, low resolutions, extra fingers, blur, blurry, ugly, wrongs proportions, watermark, image artifacts, lowres, ugly, jpeg artifacts, deformed, noisy image\"\n",
    "num_samples=4\n",
    "num_inference_steps=55\n",
    "guidance_scale=6\n",
    "\n",
    "outputs = ip_model.generate(\n",
    "    pil_image=pil_image,\n",
    "    image=prompt,\n",
    "    num_samples=num_samples,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    guidance_scale=guidance_scale,\n",
    "    negative_prompt=negative_prompt,\n",
    "    prompt=\"A good beach and a couple ahead\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image_grid(outputs, rows=1, cols=num_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
