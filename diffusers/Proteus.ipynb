{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c137d816",
   "metadata": {},
   "source": [
    "# Proteus\n",
    "\n",
    "## [ProteusV0.3](https://huggingface.co/dataautogpt3/ProteusV0.3)\n",
    "\n",
    "## Check for CUDA/MPS Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/captain2mac/Documents/Code/HuggingFace/ml_env/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/captain2mac/Documents/Code/HuggingFace/ml_env/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/captain2mac/Documents/Code/HuggingFace/ml_env/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/captain2mac/Documents/Code/HuggingFace/ml_env/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing torch device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.], device='mps:0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import (\n",
    "    StableDiffusionXLPipeline, \n",
    "    KDPM2AncestralDiscreteScheduler,\n",
    "    AutoencoderKL\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print (\"CUDA & MPS devices not found.\")\n",
    "\n",
    "print(\"Testing torch device\")\n",
    "torch.ones(2, device=device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b2dd9",
   "metadata": {},
   "source": [
    "## Loading the VAE autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093563c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f355bda017c84a55b8b28851d6a5d463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5ca784e7074e35978b91cbf42e7e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load VAE component\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"madebyollin/sdxl-vae-fp16-fix\", \n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950bda5f",
   "metadata": {},
   "source": [
    "## Configuring the pipeline to be used\n",
    "### Configuring the `KDPM2AncestralDiscreteScheduler` schedular for pipeline the piping to `device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db016c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_encoder/model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7547ebbc9bf4131b8bb65394e4a6eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionXLPipeline {\n",
       "  \"_class_name\": \"StableDiffusionXLPipeline\",\n",
       "  \"_diffusers_version\": \"0.24.0\",\n",
       "  \"_name_or_path\": \"dataautogpt3/ProteusV0.2\",\n",
       "  \"feature_extractor\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"force_zeros_for_empty_prompt\": true,\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"KDPM2AncestralDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the pipeline\n",
    "model_v2 = \"dataautogpt3/ProteusV0.2\"\n",
    "model_v3 = \"dataautogpt3/ProteusV0.3\"\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    model_v3, \n",
    "    vae=vae,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.scheduler = KDPM2AncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(device)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e09e57",
   "metadata": {},
   "source": [
    "## Actual prompting\n",
    "\n",
    "### Inputs:\n",
    "- `prompt`: The prompt to the pipeline\n",
    "- `negative_prompt `: What you don't wanna see\n",
    "- `cfg_scale`: 8 or 7\n",
    "- `guidance_scale`: Higher will be closer to prompt but quality may be affected\n",
    "  - typically around 7.5 to 10\n",
    "- `num_inference_steps`: 20 to 60, higher is slower but greater quality.\n",
    "- `images_per_prompt`: Number of output images\n",
    "- `height`: height of output image (should be divisible by 8)\n",
    "- `width`: width of output image (should be divisible by 8)\n",
    "\n",
    "### Ouput:\n",
    "- array of pillow images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78b874ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3e7dfa168a4eb28fd027176fd09eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<PIL.Image.Image image mode=RGB size=512x608>,\n",
       " <PIL.Image.Image image mode=RGB size=512x608>,\n",
       " <PIL.Image.Image image mode=RGB size=512x608>,\n",
       " <PIL.Image.Image image mode=RGB size=512x608>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define prompts and generate image\n",
    "prompt = \"Generate a visually striking Hindu OM symbol tailored for a \\\"Apple Watch\\\" wallpaper, featuring vibrant colors inspired by mountains and \\\"Lord Shiva\\\" set against a cinematic background\"\n",
    "negative_prompt = \"nsfw, bad quality, bad anatomy, worst quality, low quality, low resolutions, extra fingers, blur, blurry, ugly, wrongs proportions, watermark, image artifacts, lowres, ugly, jpeg artifacts, deformed, noisy image\"\n",
    "cfg_scale = 8\n",
    "guidance_scale = 10\n",
    "num_inference_steps = 42\n",
    "images_per_prompt = 4\n",
    "(width, height) = (512, 608)\n",
    "\n",
    "images = pipe(\n",
    "    prompt, \n",
    "    negative_prompt=negative_prompt, \n",
    "    width=width,\n",
    "    height=height,\n",
    "    num_images_per_prompt=images_per_prompt,\n",
    "    guidance_scale=guidance_scale,\n",
    "    cfg_scale=cfg_scale,\n",
    "    num_inference_steps=num_inference_steps\n",
    ").images\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a74ae",
   "metadata": {},
   "source": [
    "### Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96dad6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17-31-39\n",
      "17-31-41\n",
      "17-31-42\n",
      "17-31-43\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "for image in images:\n",
    "    now = datetime.now()\n",
    "    current = now.strftime(\"%H-%M-%S\")\n",
    "    print(current)\n",
    "    image.save(f\"../outputs/om{current}.png\")\n",
    "    sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
